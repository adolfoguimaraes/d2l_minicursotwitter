{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minicurso: O que o twitter está pensando?\n",
    "\n",
    "Estes tutoriais apresentam os principais scritps desenvolvidos no minicurso: **O que o twitter está pensando? Extraindo informações em redes sociais utilizando Python**. Os arquivos completos dos scritps e códigos gerados podem ser encontrados nas pastas **scritps** e **web** na raiz do repositório.\n",
    "\n",
    "A apresentação referente a este minicurso está disponível no site: www.data2learning.com/cursos.\n",
    "\n",
    "## 02 - Coletando Dados do Twitter (Parte 2)\n",
    "\n",
    "Na primeira parte do tutorial vimos como utilizar o método **search** para realizar a coleta de dados. Esse método permite buscar os últimos *n* twitters publicados, sendo esse *n*, normalmente, igual a 100. No entanto, para tarefas que estamos querendo fazer seria interessante deixar a coleta rodando e toda vez que algo do nosso interesse fosse postado, fosse coletado pelo nosso aplicativo. Para fazer isso, o twitter tem a chamada ***Streaming API***. Desta forma, a API do twitter permite aos desenvolvedores uma ferramenta em tempo real para coleta de dados. \n",
    "\n",
    "Informações sobre o streaming podem ser encontradas em: https://dev.twitter.com/streaming/overview\n",
    "\n",
    "Vamos criar um novo arquivo python: **streamingtwitter.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# O código a seguir não precisa ser inserido, ele é utilizado somente para que alguns imports funcionem na estrutura do Jupyter\n",
    "import sys\n",
    "sys.path.append('/Users/adolfoguimaraes/Desenvolvimento/d2l/minicursotwitter/minicursotwitter/scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# O primeiro passo é importar o Streammer e a API do Twitter\n",
    "from twython import TwythonStreamer\n",
    "from twython import Twython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe *MyStreammer* extende a classe *TwythonStreamer* do twython. Essa classe tem basicamente dois métodos: **onsuccess** e **onerror**. No primeiro iremos definir as ações para quando a coleta for realizada com sucesso. O segundo serve para fazer o tratamento de error em caso de falha na busca. \n",
    "\n",
    "O nosso arquivo ficaria como descrito a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#coding=utf8\n",
    "from twython import TwythonStreamer\n",
    "from twython import Twython\n",
    "\n",
    "class MyStreamer(TwythonStreamer):\n",
    "\n",
    "    def on_success(self, data):\n",
    "\n",
    "        print(data)\n",
    "\n",
    "    def on_error(self, status_code, data):\n",
    "\n",
    "        print(status_code)\n",
    "\n",
    "        self.disconnect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No método **on_success** apenas imprimimos o resultado da busca. A variável *data* retorna uma estrutura igual a que foi obtida quando utilizamos o método **search** na primeira etapa. Para testar a classe, vamos criar mais um arquivo python para que possamos chamar esta classe. Criem o arquivo *collecttwitter_stream.py* e inclua o código a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Primeiro precisamos importar o Stramer criado no arquivp \"streamingtwitter.py\"\n",
    "from streamingtwitter import MyStreamer\n",
    "\n",
    "#Definição das chaves da API do Twitter\n",
    "APP_KEY = None # Get Keys and Access Token at apps.twitter.com\n",
    "APP_SECRET = None # Get Keys and Access Token at apps.twitter.com\n",
    "OAUTH_TOKEN = None # Get Keys and Access Token at apps.twitter.com\n",
    "OAUTH_TOKEN_SECRET = None # Get Keys and Access Token at apps.twitter.com\n",
    "\n",
    "#E criamos nossa instância do coletor\n",
    "stream = MyStreamer(APP_KEY, APP_SECRET, OAUTH_TOKEN, OAUTH_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para iniciar a busca vamos utilizar a chamada **statuses.filter** do objeto *stream* criado. Como parâmetro vamos fazer os termos que desejamos pesquisar. Quando executado, a API vai criar tipo um \"listener\". A registro de um twitter com os termos especificados, o método **on_sucess** da sua classe *MyStreamer* vai ser chamado. O código a seguir vai coletar todos os tweets com a palavra *brasil*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stream.statuses.filter(track=\"brasil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos colocar também uma lista de termos. Nesse caso, todos os tweets que tenham pelo menos um destes termos serão coletados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stream.statuses.filter(track=\"brasil, #brasil, aracaju, #aracaju\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que a execução do **statuses.filter** incializa um processo que ficará em execução até que seja interrompido pelo usuário. Se essa não for a intensão do usuário, ele deve utilizar o método **search** como descrito anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A API do twitter permite coletar da mesma forma o que um usuário ou uma lista de usuários publica. O método é o mesmo, no entanto devemos inserir o parâmetro **follow** na busca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pode ser passado um usuário\n",
    "stream.statuses.filter(follow=\"20678688\")\n",
    "\n",
    "# Ou uma lista de usuários separados por vírgula\n",
    "stream.statuses.filter(follow=\"20678688,736392442384154624\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para descobrir o id do usuário você pode utilizar a própria API através do método **show_user**. Alguns sites permitem pegar esta informação, como por exemplo, http://mytwitterid.com/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um vez que já sabemos como coletar os dados, precisamos melhorar a apresentação dos dados coletados. Os métodos de busca trazem muitas informações, mas nem sempre queremos exbir todas. Vale ressaltar que isso depende de cada aplicação. Sendo assim, a melhor maneneira de trabalhar com estes dados é visitar sempre a API do twitter para verificar as informações que são coletadas e a partir daí analisar quais as informações são interessantes. Neste momento, vamos trabalhar somente com as informações que são relevantes para a proposta deste curso. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voltemos ao método **on_success** da classe *MyStreamer*. \n",
    "\n",
    "Este método é executado toda vez que um twitter com os critérios de busca especificado é postado. No nosso exemplo, apenas imprimimos o que é coletado no console. Vamos modificar este método para que ele imprima as informações que são de interesse e de forma mais organizada. \n",
    "\n",
    "Nosso arquivo **streamingtwitter.py** ficaria assim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding=utf8\n",
    "\n",
    "# Import dos pacotes necessários do Twython\n",
    "from twython import TwythonStreamer\n",
    "from twython import Twython\n",
    "\n",
    "# Import métodos para tratar a data\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "\n",
    "class MyStreamer(TwythonStreamer):\n",
    "    def on_success(self, data):\n",
    "        # Id do twitter\n",
    "        object_id = data['id']\n",
    "\n",
    "        # Id do usuário que postou o texto\n",
    "        user_id = data['user']['id']\n",
    "\n",
    "        # Usuário que postou o texto\n",
    "        user_name = data['user']['screen_name']\n",
    "\n",
    "        # Texto postado em utf-8\n",
    "        text = data['text'].encode('utf-8')\n",
    "\n",
    "        # Data que foi publicado\n",
    "        posted_at_tweet = data['created_at']\n",
    "\n",
    "        # Data que foi publicado formatada\n",
    "        fmt = '%Y-%m-%d %H:%M:%S.%f'\n",
    "        new_date = datetime.strptime(posted_at_tweet, '%a %b %d %H:%M:%S +0000 %Y').replace(tzinfo=pytz.UTC)\n",
    "\n",
    "        published_date = str(new_date.strftime(fmt))\n",
    "\n",
    "        tweet = {\n",
    "            'object_id': object_id,\n",
    "            'user_id': user_id,\n",
    "            'user_name': user_name,\n",
    "            'text': text,\n",
    "            'published_date': published_date,\n",
    "            'create_date': published_date,\n",
    "            'last_update': published_date,\n",
    "        }\n",
    "\n",
    "        print(tweet)\n",
    "\n",
    "    def on_error(self, status_code, data):\n",
    "        print(status_code)\n",
    "\n",
    "        self.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o que vimos até aqui é possível fazer uma coleta de dados do twitter sobre qualquer assunto. Claro que a API permite outras funcionalidades que fogem um pouco do escopo deste curso. Para os interessados, explorem mais a API em relação aos compos que ela retorna em cada busca e veja a documentação para mais detalhes.\n",
    "\n",
    "Uma vez que já sabemos como coletar, o nosso próximo passo é processar esse texto. Para esta etapa utilizaremos a API NLTK (Natural Language ToolKit) disponível em: http://www.nltk.org/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
