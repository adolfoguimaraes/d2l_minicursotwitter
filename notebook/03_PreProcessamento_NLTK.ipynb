{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minicurso: O que o twitter está pensando?\n",
    "\n",
    "Estes tutoriais apresentam os principais scritps desenvolvidos no minicurso: **O que o twitter está pensando? Extraindo informações em redes sociais utilizando Python**. Os arquivos completos dos scritps e códigos gerados podem ser encontrados nas pastas **scritps** e **web** na raiz do repositório.\n",
    "\n",
    "A apresentação referente a este minicurso está disponível no site: http://www.data2learning.com/cursos.\n",
    "\n",
    "## 03 - Pré-processamento de texto utilizando NLTK\n",
    "\n",
    "Nesta etapa vamos aprender algumas técnicas para tratar o texto que foi coletado no twitter. Incialmente vamos trabalhar com a parte de tokenização, remoção de palavras que não serão úteis, aplicação de métodos de *steammig* e retirada automática de links, hashtags do texto e outras informaçÕes relevantes que vão ser detalhadas mais a frente.\n",
    "\n",
    "O NLTK (http://www.nltk.org) não é uma ferramenta de pré-processamento, ele é um kit completo para tratar problemas relacionados ao processamento de Linguagem Natural. No entanto, ele possui alguns métodos para nos ajudar nestas tarefas iniciais. Citanto o site oficial: *NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.*.\n",
    "\n",
    "O material desenvolvido aqui é baseado, principalmente, no livro **Python 3 Text Processing with NLTK 3 Cookbook**: https://www.amazon.com.br/dp/B00N2RWMJU/.\n",
    "\n",
    "Vamos começar :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenização\n",
    "\n",
    "A primeira etapa do pré-processamento do texto coletado é separá-lo em *tokens*. Tokenizar consiste em quebrar um texto em pedaços, sejam palavras ou sentenças. Para utilizar os métodos desta etapa será necessário instalar alguns itens adicionais do NLTK.\n",
    "\n",
    "Para isso, digite na linha de comando:\n",
    "\n",
    "```shell\n",
    "$ python\n",
    "```\n",
    "\n",
    "No shell do Python digite os comandos a seguir:\n",
    "\n",
    "```python\n",
    ">>> import ntlk\n",
    ">>> nltk.download()\n",
    "NLTK Downloader                                                                                                                                       \n",
    "---------------------------------------------------------------------------                                                                           \n",
    "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit                                                                                \n",
    "---------------------------------------------------------------------------                                                                           \n",
    "Downloader> \n",
    "```\n",
    "\n",
    "Nessa tela, se digitar **l** será listado todos os pacotes que podem ser instalados. Para o nosso propósito de tokenização vamos instalar o pacote **punkt** que possui os modelos necessários para que a gente faça os diversos tipos de tokenização.\n",
    "\n",
    "```python\n",
    "Downloader> d punkt                                                                                                                                   \n",
    "    Downloading package punkt to /home/d2l/nltk_data...                                                               \n",
    "        Unzipping tokenizers/punkt.zip. \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
